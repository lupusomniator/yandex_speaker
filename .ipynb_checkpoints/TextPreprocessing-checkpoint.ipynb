{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Степан\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessing:\n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    stop_words = stopwords.words('russian')\n",
    "    \n",
    "    def __init__(self):\n",
    "        print()\n",
    "        \n",
    "    '''\n",
    "    Перевести тег слова из формата Pymorphy2 в общепринятый формат\n",
    "    '''\n",
    "    def translate_tags(self, tag: str) -> str:\n",
    "        grammars = {'NOUN': '_NOUN', 'ADJF': '_ADJ', 'ADJS': '_ADJ', 'COMP': '_IGN', 'VERB': '_VERB', 'INFN': '_VERB',\n",
    "                    'GRND': '_VERB', 'PRTF': '_VERB', 'PRTS': '_VERB', 'NUMR': '_NUM', 'ADVB': '_ADV', 'NPRO': '_PRON',\n",
    "                    'PRED': '_ADV', 'PREP': '_ADP', 'CONJ': '_CCONJ', 'PRCL': '_PART', 'INTJ': '_INTJ'}\n",
    "        if tag in grammars:\n",
    "            return grammars[tag]\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "    '''\n",
    "    Удалить всю пунктуацию в предложении\n",
    "    '''\n",
    "    def remove_punctuation(self, s: str) -> str:\n",
    "        return ''.join(c if c not in punctuation else ' ' for c in s)\n",
    "    \n",
    "    '''\n",
    "    Выполнить предобработку одного предложения\n",
    "    '''\n",
    "    def preprocess_sentence(self, sentence: str)-> list: \n",
    "        normalized = []\n",
    "        # Удаляем всю пунктуацию в предложении и\n",
    "        # объеденяем слова в предложении в список\n",
    "        sentence_list = self.remove_punctuation(sentence).split()\n",
    "        \n",
    "        # Для каждого слова в предложении\n",
    "        for word in sentence_list:\n",
    "            # Проверка на отсутствие слова в списке стоп-слов\n",
    "            if word in self.stop_words:\n",
    "                continue\n",
    "            # Находим все возможные варианты разбора слова    \n",
    "            forms = self.morph.parse(word)\n",
    "            #print(forms[0].method_stack)\n",
    "            #print(forms)\n",
    "            try:\n",
    "                # Выбираем наиболее вероятный вариант\n",
    "                form = max(forms, key=lambda x: x.score)\n",
    "            except Exception:\n",
    "                # Если разбор слова не удался, просто оставляем его как есть\n",
    "                form = forms[0]\n",
    "            # Если не удалось определить тип слова или нормальная форма слова находится в стоп-словах       \n",
    "            if not ('Name' in form.tag or 'UNKN' in form.tag or 'LATN' in form.tag or form.normal_form in self.stop_words):\n",
    "                # RusVectories требует отсутствия букв ё\n",
    "                #if form.normal_form.replace('ё', 'е') + self.translate_tags(form.tag.POS) in word_vec:\n",
    "                normalized.append(form.normal_form.replace('ё', 'е') + self.translate_tags(form.tag.POS))\n",
    "        # else:\n",
    "        #     normalized.append(word)\n",
    "        return normalized\n",
    "    \n",
    "    '''\n",
    "    Выполнить предобработку корпуса предложений\n",
    "    '''\n",
    "    def preprocess_text(self, sentence_list: list) -> list:\n",
    "        result = []\n",
    "        for sentence in sentence_list:\n",
    "            result.append(preprocess_sentence(sentence))\n",
    "        return result\n",
    "    \n",
    "    '''\n",
    "    Выполнить предобработку корпуса предложений\n",
    "    '''\n",
    "    def list_to_text(self, sentence_list: list) -> str:\n",
    "        return ' '.join(word for word in sentence_list)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    p = TextPreprocessing()\n",
    "    print(p.preprocess_sentence(\"!@#$%^&*().,/<>\\{}[]\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
